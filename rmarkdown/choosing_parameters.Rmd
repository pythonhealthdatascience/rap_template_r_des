---
title: "Choosing parameters"
author: "Amy Heather"
date: "`r Sys.Date()`"
output:
  github_document:
      toc: true
---

This notebook documents the choice of simulation parameters including:

* Number of replications
* Number of CPU cores

The generated images are saved and then loaded, so that we view the image as saved (i.e. with the dimensions set in `ggsave()`). This also avoids the creation of a `_files/` directory when knitting the document (which would save all previewed images into that folder also, so they can be rendered and displayed within the output `.md` file, even if we had not specifically saved them). These are viewed using `include_graphics()`, which must be the last command in the cell (or last in the plotting function).

The run time is provided at the end of the notebook.

## Set up

Install the latest version of the local simulation package.

```{r}
devtools::install()
```

Load required packages.

```{r}
# nolint start: undesirable_function_linter.
library(data.table)
library(dplyr)
library(ggplot2)
library(knitr)
library(simulation)
library(tidyr)

options(data.table.summarise.inform = FALSE)
options(dplyr.summarise.inform = FALSE)
# nolint end
```

Start timer.

```{r}
start_time <- Sys.time()
```

Define path to outputs folder.

```{r}
output_dir <- file.path("..", "outputs")
```

## Choosing the number of replications

The **confidence interval method** can be used to select the number of replications to run. The more replications you run, the narrower your confidence interval becomes, leading to a more precise estimate of the model's mean performance.

First, you select a desired confidence interval - for example, 95%. Then, run the model with an increasing number of replications, and identify the number required to achieve that precision in the estimate of a given metric - and also, to maintain that precision (as the intervals may converge or expand again later on).

This method is less useful for values very close to zero - so, for example, when using utilisation (which ranges from 0 to 1) it is recommended to multiple values by 100.

When selecting the number of replications you should repeat the analysis for all performance measures and select the highest value as your number of replications.

```{r}
#' Use the confidence interval method to select the number of replications.
#'
#' @param replications Number of times to run the model.
#' @param desired_precision Desired mean deviation from confidence interval.
#' @param metric Name of performance metric to assess.
#' @param yaxis_title Label for y axis.
#' @param file Filename to save figure to.
#' @param min_rep A suggested minimum number of replications (default=NULL).

confidence_interval_method <- function(replications, desired_precision, metric,
                                       yaxis_title, file, min_rep = NULL) {
  # Run model for specified number of replications
  param_class <- defaults()
  param_class[["update"]](list(number_of_runs = replications))
  envs <- trial(param_class)
  results <- process_replications(envs)

  # If mean of metric is less than 1, multiply by 100
  if (mean(results[[metric]]) < 1L) {
    results[[paste0("adj_", metric)]] <- results[[metric]] * 100L
    metric <- paste0("adj_", metric)
  }

  # Initialise list to store the results
  cumulative_list <- list()

  # For each row in the dataframe, filter to rows up to the i-th replication
  # then perform calculations
  for (i in 1L:replications) {

    # Filter rows up to the i-th replication
    subset <- results[[metric]][1L:i]

    # Calculate mean
    mean <- mean(subset)

    # Some calculations require more than 1 observation else will error...
    if (i == 1L) {
      # When only one observation, set to NA
      std_dev <- NA
      ci_lower <- NA
      ci_upper <- NA
      deviation <- NA
    } else {
      # Else, calculate standard deviation, 95% confidence interval, and
      # percentage deviation
      std_dev <- sd(subset)
      ci <- t.test(subset)[["conf.int"]]
      ci_lower <- ci[[1L]]
      ci_upper <- ci[[2L]]
      deviation <- ((ci_upper - mean) / mean) * 100L
    }

    # Append to the cumulative list
    cumulative_list[[i]] <- data.frame(
      replications = i,
      cumulative_mean = mean,
      cumulative_std = std_dev,
      ci_lower = ci_lower,
      ci_upper = ci_upper,
      perc_deviation = deviation
    )
  }

  # Combine the list into a single data frame
  cumulative <- do.call(rbind, cumulative_list)

  # Get the minimum number of replications where deviation is less than target
  compare <- cumulative %>%
    filter(.data[["perc_deviation"]] <= desired_precision * 100L)
  if (nrow(compare) > 0L) {
    # Get minimum number
    n_reps <- compare %>%
      slice_head() %>%
      dplyr::select(replications) %>%
      pull()
    print(paste0("Reached desired precision (", desired_precision, ") in ",
                 n_reps, " replications."))
  } else {
    warning("Running ", replications, " replications did not reach ",
            "desired precision (", desired_precision, ").")
  }

  # Plot the cumulative mean and confidence interval
  p <- ggplot(cumulative, aes(x = .data[["replications"]],
                              y = .data[["cumulative_mean"]])) +
    geom_line() +
    geom_ribbon(aes(ymin = ci_lower, ymax = ci_upper), alpha = 0.2)

  # If specified, plot the minimum suggested number of replications
  if (!is.null(min_rep)) {
    p <- p +
      geom_vline(xintercept = min_rep, linetype = "dashed", color = "red")
  }

  # Modify labels and style
  p <- p +
    labs(x = "Replications", y = yaxis_title) +
    theme_minimal()

  # Save the plot
  full_path <- file.path(output_dir, file)
  ggsave(filename = full_path, width = 6.5, height = 4L, bg = "white")

  # View the plot
  include_graphics(full_path)
}
```

```{r}
confidence_interval_method(
  replications = 70L,
  desired_precision = 0.05,
  metric = "mean_activity_time_nurse",
  yaxis_title = "Mean time with nurse",
  file = "choose_param_conf_int_1.png",
  min_rep = 66L
)
```

It's important to check ahead, to check that the 5% precision is maintained.

```{r}
confidence_interval_method(
  replications = 100L,
  desired_precision = 0.05,
  metric = "mean_activity_time_nurse",
  yaxis_title = "Mean time with nurse",
  file = "choose_param_conf_int_2.png",
  min_rep = 66L
)
```

Also, to check across multiple metrics.

```{r}
confidence_interval_method(
  replications = 200L,
  desired_precision = 0.05,
  metric = "utilisation_nurse",
  yaxis_title = "Mean nurse utilisation",
  file = "choose_param_conf_int_3.png",
  min_rep = 136L
)
```

## Run time with varying number of CPU cores

```{r}
#' Run model with 1 to 8 CPU cores and examine run times
#'
#' @param file Filename to save figure to.
#' @param model_param List of parameters for the model.

run_cores <- function(file, model_param = NULL) {
  # Run model with 1 to 8 cores
  speed <- list()
  for (i in 1L:8L){
    print(paste("Running with cores:", i))
    cores_start <- Sys.time()

    # Run model with specified number of cores
    # If specified, also set to provided model parameters
    param_class <- defaults()
    if (!is.null(model_param)) {
      param_class[["update"]](model_param)
    }
    param_class[["update"]](list(cores = i))
    invisible(trial(param_class))

    # Record time taken
    cores_time <- as.numeric(Sys.time() - cores_start, units = "secs")
    speed[[i]] <- list(cores = i, run_time = round(cores_time, 3L))
  }

  # Convert to dataframe
  speed_df <- rbindlist(speed)

  # Generate plot
  p <- ggplot(speed_df, aes(x = .data[["cores"]], y = .data[["run_time"]])) +
    geom_line() +
    labs(x = "Cores", y = "Run time (seconds)") +
    theme_minimal()

  # Save plot
  full_path <- file.path(output_dir, file)
  ggsave(filename = full_path, plot = p,
         width = 6.5, height = 4L, bg = "white")

  # View the plot
  include_graphics(full_path)
}
```

Setting up and managing a parallel cluster takes extra time. For small tasks or few iterations, this extra time can be more than the time saved by running in parallel.

```{r}
run_cores("cores1.png")
```

Having increased the simulation length, we now see that parallelisation is increasing the model run time.

However, when you use more cores, the data needs to be divided and sent to more workers. For small tasks, this extra work is small, but as the number of workers increases, the time spent managing and communicating with them can grow too much. At some point, this overhead becomes larger than the time saved by using more cores.

The optimal number of cores will vary depending on your model parameters and machine.

```{r}
run_cores("cores2.png", list(data_collection_period = 10000L))
```

## Run time

```{r end_timer}
# Get run time in seconds
end_time <- Sys.time()
runtime <- as.numeric(end_time - start_time, units = "secs")

# Display converted to minutes and seconds
minutes <- as.integer(runtime / 60L)
seconds <- as.integer(runtime %% 60L)
print(sprintf("Notebook run time: %dm %ds", minutes, seconds))
```
